{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8102913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import joblib\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23010e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALLERGY': 0, 'COLD': 1, 'COVID': 2, 'FLU': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperates input and output\n",
    "df = pd.read_csv(\"symptoms.csv\")\n",
    "\n",
    "dictionary = dict(ALLERGY = 0, COLD = 1, COVID = 2, FLU = 3)\n",
    "print(dictionary)\n",
    "\n",
    "predict = 'TYPE'\n",
    "X = df.drop(columns=predict)\n",
    "y = df[predict]\n",
    "\n",
    "colnames = X.columns\n",
    "\n",
    "#Splitting up into train and test\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086d2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1112/1112 [==============================] - 7s 5ms/step - loss: 0.1866 - accuracy: 0.9176\n",
      "Epoch 2/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1091 - accuracy: 0.9305\n",
      "Epoch 3/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1070 - accuracy: 0.9340\n",
      "Epoch 4/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1060 - accuracy: 0.9327\n",
      "Epoch 5/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1059 - accuracy: 0.9318\n",
      "Epoch 6/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1053 - accuracy: 0.9317\n",
      "Epoch 7/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1048 - accuracy: 0.9321\n",
      "Epoch 8/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1047 - accuracy: 0.9325\n",
      "Epoch 9/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.1042 - accuracy: 0.9309\n",
      "Epoch 10/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1037 - accuracy: 0.9316\n",
      "Epoch 11/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1033 - accuracy: 0.9330\n",
      "Epoch 12/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1029 - accuracy: 0.9330\n",
      "Epoch 13/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1024 - accuracy: 0.9317\n",
      "Epoch 14/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1025 - accuracy: 0.9334\n",
      "Epoch 15/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1023 - accuracy: 0.9333\n",
      "Epoch 16/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1021 - accuracy: 0.9322\n",
      "Epoch 17/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1020 - accuracy: 0.9330\n",
      "Epoch 18/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1017 - accuracy: 0.9335\n",
      "Epoch 19/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1018 - accuracy: 0.9313\n",
      "Epoch 20/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1014 - accuracy: 0.9327\n",
      "Epoch 21/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1014 - accuracy: 0.9327\n",
      "Epoch 22/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1013 - accuracy: 0.9323\n",
      "Epoch 23/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1013 - accuracy: 0.9329\n",
      "Epoch 24/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1011 - accuracy: 0.9330\n",
      "Epoch 25/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1011 - accuracy: 0.9343\n",
      "Epoch 26/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1012 - accuracy: 0.9324\n",
      "Epoch 27/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1008 - accuracy: 0.9329\n",
      "Epoch 28/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1010 - accuracy: 0.9336\n",
      "Epoch 29/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1008 - accuracy: 0.9323\n",
      "Epoch 30/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.1007 - accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1008 - accuracy: 0.9318\n",
      "Epoch 32/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1006 - accuracy: 0.9335\n",
      "Epoch 33/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1006 - accuracy: 0.9324\n",
      "Epoch 34/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1005 - accuracy: 0.9346\n",
      "Epoch 35/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1005 - accuracy: 0.9320\n",
      "Epoch 36/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1005 - accuracy: 0.9348\n",
      "Epoch 37/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1004 - accuracy: 0.9329\n",
      "Epoch 38/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1002 - accuracy: 0.9330\n",
      "Epoch 39/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1004 - accuracy: 0.9328\n",
      "Epoch 40/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1002 - accuracy: 0.9347\n",
      "Epoch 41/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1001 - accuracy: 0.9337\n",
      "Epoch 42/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1001 - accuracy: 0.9343\n",
      "Epoch 43/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1002 - accuracy: 0.9334\n",
      "Epoch 44/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0999 - accuracy: 0.9344\n",
      "Epoch 45/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1000 - accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0999 - accuracy: 0.9334\n",
      "Epoch 47/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.1000 - accuracy: 0.9335\n",
      "Epoch 48/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0998 - accuracy: 0.9351\n",
      "Epoch 49/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0998 - accuracy: 0.9335\n",
      "Epoch 50/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0997 - accuracy: 0.9325\n",
      "Epoch 51/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0996 - accuracy: 0.9328\n",
      "Epoch 52/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0997 - accuracy: 0.9331\n",
      "Epoch 53/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0997 - accuracy: 0.9337\n",
      "Epoch 54/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0994 - accuracy: 0.9341\n",
      "Epoch 55/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0994 - accuracy: 0.9335\n",
      "Epoch 56/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0998 - accuracy: 0.9334\n",
      "Epoch 57/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0993 - accuracy: 0.9340\n",
      "Epoch 58/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0994 - accuracy: 0.9337\n",
      "Epoch 59/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0994 - accuracy: 0.9336\n",
      "Epoch 60/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0994 - accuracy: 0.9344\n",
      "Epoch 61/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0993 - accuracy: 0.9329\n",
      "Epoch 62/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0992 - accuracy: 0.9347\n",
      "Epoch 63/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0992 - accuracy: 0.9340\n",
      "Epoch 64/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0991 - accuracy: 0.9341\n",
      "Epoch 65/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0990 - accuracy: 0.9350\n",
      "Epoch 66/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0990 - accuracy: 0.9352\n",
      "Epoch 67/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0989 - accuracy: 0.9340\n",
      "Epoch 68/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0989 - accuracy: 0.9336\n",
      "Epoch 69/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0988 - accuracy: 0.9345\n",
      "Epoch 70/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0990 - accuracy: 0.9337\n",
      "Epoch 71/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0987 - accuracy: 0.9343\n",
      "Epoch 72/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0987 - accuracy: 0.9351\n",
      "Epoch 73/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0988 - accuracy: 0.9346\n",
      "Epoch 74/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0986 - accuracy: 0.9354\n",
      "Epoch 75/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0988 - accuracy: 0.9353\n",
      "Epoch 76/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0986 - accuracy: 0.9341\n",
      "Epoch 77/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0984 - accuracy: 0.9348\n",
      "Epoch 78/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0984 - accuracy: 0.9349\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0983 - accuracy: 0.9356\n",
      "Epoch 80/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.0984 - accuracy: 0.9353\n",
      "Epoch 81/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0981 - accuracy: 0.9345\n",
      "Epoch 82/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0984 - accuracy: 0.9343\n",
      "Epoch 83/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.0980 - accuracy: 0.9346\n",
      "Epoch 84/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0980 - accuracy: 0.9359\n",
      "Epoch 85/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0981 - accuracy: 0.9349\n",
      "Epoch 86/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0978 - accuracy: 0.9353\n",
      "Epoch 87/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0981 - accuracy: 0.9351\n",
      "Epoch 88/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0980 - accuracy: 0.9352\n",
      "Epoch 89/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0978 - accuracy: 0.9348\n",
      "Epoch 90/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0980 - accuracy: 0.9352\n",
      "Epoch 91/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0977 - accuracy: 0.9359\n",
      "Epoch 92/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.0978 - accuracy: 0.9342\n",
      "Epoch 93/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0979 - accuracy: 0.9334\n",
      "Epoch 94/100\n",
      "1112/1112 [==============================] - 4s 4ms/step - loss: 0.0978 - accuracy: 0.9346\n",
      "Epoch 95/100\n",
      "1112/1112 [==============================] - 91s 82ms/step - loss: 0.0976 - accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0977 - accuracy: 0.9369\n",
      "Epoch 97/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.0976 - accuracy: 0.9361\n",
      "Epoch 98/100\n",
      "1112/1112 [==============================] - 5s 5ms/step - loss: 0.0977 - accuracy: 0.9353\n",
      "Epoch 99/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0975 - accuracy: 0.9363\n",
      "Epoch 100/100\n",
      "1112/1112 [==============================] - 5s 4ms/step - loss: 0.0976 - accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "#Creating model\n",
    "m=X_train.shape[0]\n",
    "n=X_train.shape[1]\n",
    "\n",
    "#Creating the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(n,), activation='relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'sigmoid'))\n",
    "\n",
    "#Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Chaning y_test into form that can be put into model\n",
    "y_binary = keras.utils.to_categorical(y_train, num_classes=4, dtype='int')\n",
    "\n",
    "#Fit the keras model on the dataset\n",
    "model.fit(X_train, y_binary, epochs=100, verbose = 1)\n",
    "\n",
    "#Saving the model\n",
    "model.save('Symptoms_Keras_Model.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8508e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\1609798684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616f7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112/1112 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#Making Predictions with saved model\n",
    "\n",
    "\n",
    "model = load_model(\"Symptoms_Keras_Model.h5\") #Loads model\n",
    "predictions = model.predict(X_train) #Makes Predictions\n",
    "\n",
    "\n",
    "#Converting predictions into 1s and 0s\n",
    "for i in range(m):\n",
    "    maxNum = predictions[i].max()\n",
    "    for k in range(0, 4):      \n",
    "        if predictions[i] [k] == maxNum:\n",
    "            predictions[i] [k] = 1\n",
    "        else:\n",
    "            predictions[i] [k] = 0\n",
    "    \n",
    "#Making predictions into int\n",
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e84f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     13042\n",
      "           1       0.62      0.61      0.61       820\n",
      "           2       0.52      0.83      0.64      1646\n",
      "           3       0.98      0.92      0.95     20054\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     35562\n",
      "   macro avg       0.77      0.84      0.80     35562\n",
      "weighted avg       0.95      0.94      0.94     35562\n",
      " samples avg       0.94      0.94      0.94     35562\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_binary, predictions)\n",
    "print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "print('Classification Report:')\n",
    "print(sklearn.metrics.classification_report(y_binary, predictions))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8b216f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 1s 4ms/step\n",
      "Accuracy: 91.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3339\n",
      "           1       0.43      0.47      0.45       204\n",
      "           2       0.45      0.70      0.55       402\n",
      "           3       0.97      0.91      0.94      4946\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8891\n",
      "   macro avg       0.71      0.77      0.73      8891\n",
      "weighted avg       0.93      0.92      0.92      8891\n",
      " samples avg       0.92      0.92      0.92      8891\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predictions with test data\n",
    "model = load_model(\"Symptoms_Keras_Model.h5\") #Loads model\n",
    "predictions = model.predict(X_test) #Makes Predictions\n",
    "\n",
    "\n",
    "m1=y_test.shape[0]\n",
    "y_test=np.asarray(y_test).astype('int32')\n",
    "y_binary_test = keras.utils.to_categorical(y_test, num_classes=4, dtype='int')\n",
    "#Converting predictions into 1s and 0s\n",
    "for i in range(m1):\n",
    "    maxNum = predictions[i].max()\n",
    "    for k in range(0, 4):      \n",
    "        if predictions[i] [k] == maxNum:\n",
    "            predictions[i] [k] = 1\n",
    "        else:\n",
    "            predictions[i] [k] = 0\n",
    "    \n",
    "#Making predictions into int\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "#Accuracy of predictions\n",
    "accuracy = sklearn.metrics.accuracy_score(y_binary_test, predictions)\n",
    "print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "print('Classification Report:')\n",
    "print(sklearn.metrics.classification_report(y_binary_test, predictions))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # It can be used to reconstruct the model identically.\n",
    "# n=colnames.shape[0]\n",
    "# test_input=[]\n",
    "# for i in range(n):\n",
    "#     print(\"Do you have \", colnames[i], \"?? Enter 1 for Yes and 0 for No-\")\n",
    "#     inp = input()\n",
    "#     test_input.append(inp)\n",
    "# test_input=np.asarray(test_input)\n",
    "# test_input = test_input.reshape(1, -1)  #reshaping because right now shape of array is (n,) which has to be converted to (1,n)\n",
    "# test_input = scaler.transform(test_input)\n",
    "# key_list = list(dictionary.keys()) #make a list of keys \n",
    "# val_list = list(dictionary.values()) #make a list of values \n",
    "\n",
    "# # load the Neural Network model from disk\n",
    "# nn_model = keras.models.load_model(\"Symptoms_Keras_Model.h5\")\n",
    "\n",
    "# prediction1=nn_model(test_input) \n",
    "# prediction1=np.asarray(prediction1)\n",
    "# max_index_col = np.argmax(prediction1, axis=1) #find the max value in the output vector\n",
    "# print(\"Neural Network says you have\", key_list[val_list.index(max_index_col)], \"with, {0:.2f}\".format(accuracy * 100.0), \"accuracy\") #printing the key value wrt the output given by NN\n",
    "# #print(prediction1)\n",
    "\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "n=colnames.shape[0]\n",
    "test_input=[]\n",
    "for i in range(n):\n",
    "    print(\"Do you have \", colnames[i], \"?? Enter 1 for Yes and 0 for No-\")\n",
    "    inp=input()\n",
    "    test_input.append(inp)\n",
    "test_input=np.asarray(test_input)\n",
    "test_input = test_input.reshape(1, -1)  #reshaping because right now shape of array is (n,) which has to be converted to (1,n)\n",
    "test_input = scaler.transform(test_input)\n",
    "key_list = list(dictionary.keys()) #make a list of keys \n",
    "val_list = list(dictionary.values()) #make a list of values \n",
    "\n",
    "# load the Neural Network model from disk\n",
    "nn_model = keras.models.load_model(\"Symptoms_Keras_Model.h5\")\n",
    "\n",
    "prediction1=nn_model(test_input) \n",
    "prediction1=np.asarray(prediction1)\n",
    "max_index_col = np.argmax(prediction1, axis=1) #find the max value in the output vector\n",
    "print(\"NN says you have\", key_list[val_list.index(max_index_col)]) #printing the key value wrt the output given by NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f855a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
